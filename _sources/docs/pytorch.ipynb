{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c6bf05-2e31-46b6-8a24-6e8bac97382d",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "[PyTorch](https://en.wikipedia.org/wiki/PyTorch) is a machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing. PyTorch provides two high-level features:\n",
    "\n",
    "- Tensor computing with acceleration via graphics processing units (GPUs)\n",
    "- Deep neural networks built on a tape-based automatic differentiation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f044dec-3842-4719-af51-781875b9c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb2939-a279-4162-b8f1-0b51b521235a",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "The central data abstraction in PyTorch is given by the `torch.tensor` class. It represents the counterpart of the `numpy.ndarray` class in NumPy, and many of the respective class methods have similar syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659ecc5c-383a-4d12-8080-e74895567339",
   "metadata": {},
   "source": [
    "### Tensor creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96366641-264e-4043-8f5c-d073ed9edb35",
   "metadata": {},
   "source": [
    "Ways to create PyTorch tensors include:\n",
    "\n",
    "- `torch.tensor()`\n",
    "- `torch.empty()`\n",
    "- `torch.zeros()`\n",
    "- `torch.ones()`\n",
    "- `torch.rand()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eccc351-9363-4820-be60-bf22b527ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3, 3, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a7c974-c503-4868-acf1-dd4f07f91bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1264, 0.2128, 0.4394],\n",
      "        [0.1689, 0.6541, 0.3996],\n",
      "        [0.9370, 0.2361, 0.0902]])\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310b3be-bf97-4ffd-992c-336a51a10896",
   "metadata": {},
   "source": [
    "By default, PyTorch tensors are populated with 32-bit (single precision) floating point numbers suitable for arithmetic operations on GPUs, but many other data types are available and include:\n",
    "\n",
    "- `torch.bool`\n",
    "- `torch.int8`\n",
    "- `torch.int16`\n",
    "- `torch.int32`\n",
    "- `torch.int64`\n",
    "- `torch.half` or `torch.float16`\n",
    "- `torch.float`\n",
    "- `torch.double` or `torch.float64`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaabecd-9cf0-4946-9bc5-129b989b2472",
   "metadata": {},
   "source": [
    "A PyTorch tensor can be converted to a regular Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01f18192-e2d7-4ca6-897d-6a7821306aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.12643754482269287, 0.2127731442451477, 0.4393724799156189],\n",
       " [0.16894280910491943, 0.6540544033050537, 0.39956939220428467],\n",
       " [0.9369684457778931, 0.23605263233184814, 0.09021276235580444]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6175487-afd5-4275-9636-9478f001c5da",
   "metadata": {},
   "source": [
    "Conversely, a Python list can be converted to a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88abbc97-078a-454a-b2be-9ebabd727162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1264, 0.2128, 0.4394],\n",
       "        [0.1689, 0.6541, 0.3996],\n",
       "        [0.9370, 0.2361, 0.0902]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(a.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e0d98-581a-4578-a4e0-8d3254699069",
   "metadata": {},
   "source": [
    "### Tensor operations\n",
    "\n",
    "PyTorch tensors have over three hundred operations that can be performed on them, including:\n",
    "\n",
    "- `torch.abs()`\n",
    "- `torch.max()`\n",
    "- `torch.mean()`\n",
    "- `torch.std()`\n",
    "- `torch.prod()`\n",
    "- `torch.unique()`\n",
    "- `torch.matmul()`\n",
    "- `torch.svd()`\n",
    "- `torch.sin()`\n",
    "- `torch.cos()`\n",
    "- `torch.flatten()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa48c00b-0b64-49c9-9a1a-5519930c21ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3627)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e0309c-93df-4509-8867-e3a6f4b80a8e",
   "metadata": {},
   "source": [
    "Note that a tensor with a scalar number is given in return. To instead get a Python number in return, we can perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca4d6f69-69a2-4531-9326-4c34125c3d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36270925402641296"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8802d60a-d627-4247-ab5d-83f97642def9",
   "metadata": {},
   "source": [
    "### NumPy bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5d2bf4-cb2c-43a8-aa2c-8cbb741340e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51233599-9c2d-4c5e-aa27-48cb2a79ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.ones((2, 3))\n",
    "pth_tensor = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "498c2ae8-55b3-4760-85ff-dd502be0615f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(pth_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5f1f5-299f-4b7c-82c8-82540e71f047",
   "metadata": {},
   "source": [
    "We note that the NumPy array default data type of float64 (double precision) is preserved. In fact, we merely created a pointer to the same data in memory such that a change in one object is reflected in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f44bd8d-3e35-4a37-a17b-44bb600e9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array[1, 2] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bee37edc-ac34-41aa-81bd-b072c35241ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified numpy array:\n",
      " [[1. 1. 1.]\n",
      " [1. 1. 2.]]\n",
      "Bridged pytorch tensor:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Modified numpy array:\\n\", np_array)\n",
    "print(\"Bridged pytorch tensor:\\n\", pth_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1471e1c6-44ec-434d-a292-bd767ddafba4",
   "metadata": {},
   "source": [
    "A reason to create a bridge between data can e.g. be to take advantage of the easy accessible  GPU acceleration available in PyTorch for scientific codes developed with NumPy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cd2249-5563-47a5-9120-f80601180f15",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7943a0e9-7780-4e50-91c0-f447e8aef8ea",
   "metadata": {},
   "source": [
    "The machine learning models in PyTorch are built as neural networks with layers of neurons. The input layers received input data; hidden layers transforms the data; and the output layer provides the results upon which model predictions are made.\n",
    "\n",
    "Every neuron has an associated activation level. The input level apart, activation levels in a given level, say $L$, are determined from those in the previous layer by use of weights that are collected in a matrix $\\boldsymbol{W}$ and biases that are collected in a row vector $\\boldsymbol{b}$. \n",
    "\n",
    "A layer is referred to as *linear* if the weights and biases are applied in a linear transformation\n",
    "\n",
    "$$\n",
    "\\boldsymbol{a}^{(L)} = f(\\boldsymbol{a}^{(L-1)} \\boldsymbol{W}^T \n",
    "+ \\boldsymbol{b})\n",
    "$$\n",
    "\n",
    "As indicated, to get the final activation levels also involves the elementwise operation of a  (typically) nonlinear activation function, $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80d91b9-fa63-4284-86dc-4b721e50aab7",
   "metadata": {},
   "source": [
    "![Neural Network](../images/neural_network.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e825b-c1b7-4201-9e95-e73f0dff4b3e",
   "metadata": {},
   "source": [
    "### Flatten tensors\n",
    "\n",
    "PyTorch receives input data in the form of batches of PyTorch tensors of rank 1. If data is stored as tensors of higher rank, they first need to be flattened. \n",
    "\n",
    "Let us assume having three $2\\times 2$ tensors as input, e.g. three greyscale images of two-by-two pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37d1fc2a-87d7-4a51-9789-ae0d23702b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "\n",
    "tensor_batch = torch.rand(batch_size, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42847885-e3f7-43c6-9556-d7a7b921fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = torch.nn.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cf9ab92-95f1-41c2-8fec-ca3dd7f4ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = flatten(tensor_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b418d45-34f4-4583-ba12-aaedb98ab6a2",
   "metadata": {},
   "source": [
    "These have now been flattened to become three row vectors of dimension four."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b4d3ae-41a4-4a9d-bb8d-daaf327b0f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7347, 0.9150, 0.3196, 0.1653],\n",
      "        [0.3985, 0.5302, 0.5364, 0.3005],\n",
      "        [0.2823, 0.5272, 0.7644, 0.2547]])\n"
     ]
    }
   ],
   "source": [
    "print(a0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745fd18-740c-4dc8-b491-61053c623cb3",
   "metadata": {},
   "source": [
    "### Layer transformations\n",
    "\n",
    "The linear layer transformation described above is achieved with the `torch.nn.Linear` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de014504-c10b-4909-8a0a-c4a0d885a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(4, 2, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ee301-14b9-4a1b-afa1-7c261c513558",
   "metadata": {},
   "source": [
    "Here we consider a transformation from an input layer with four neurons, $n_0 = 4$, to a hidden layer with only two, $n_1 = 2$.\n",
    "\n",
    "When instantiated, the hidden layer object receives weight and bias attributes that are initialized randomly with values\n",
    "\n",
    "$$\n",
    "-1/\\sqrt{n_0} < w_{ij}, b_i < 1 / \\sqrt{n_0}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e31176b8-a828-4448-af13-960a2b663e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2979, -0.1393, -0.1280,  0.2627],\n",
       "        [ 0.0665,  0.0518,  0.2140,  0.1802]], requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0cefe79-513f-461a-8556-0fbd8201bae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.3289, -0.3964], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0698d17-e8da-4450-b85c-3dec87c97e65",
   "metadata": {},
   "source": [
    "Use PyToch to perform the layer transoformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac750bcc-4ebc-4442-89ad-d8ab601228b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4229, -0.2020],\n",
       "        [ 0.3840, -0.1735],\n",
       "        [ 0.3086, -0.1409]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(a0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0301857-d985-4791-ac59-b02e73e40d33",
   "metadata": {},
   "source": [
    "Check the transformation with an explicit calculation of the linear transformation:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{a}^{(0)} \\boldsymbol{W}^T \n",
    "+ \\boldsymbol{b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0cda628-033f-4d8b-b9d1-6207c06f02f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4229, -0.2020],\n",
       "        [ 0.3840, -0.1735],\n",
       "        [ 0.3086, -0.1409]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a0, linear.weight.T) + linear.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47851075-f623-49ce-a88f-bb75c4030322",
   "metadata": {},
   "source": [
    "We note that the two results are identical.\n",
    "\n",
    "Now remains the application of the nonlinear activation function, $f$, according to\n",
    "\n",
    "$$\n",
    "\\boldsymbol{a}^{(1)} =f( \n",
    "\\boldsymbol{a}^{(0)} \\boldsymbol{W}^T \n",
    "+ \\boldsymbol{b})\n",
    "$$\n",
    "\n",
    "A common choice in machine learning is to adopt the rectifier linear unit function\n",
    "\n",
    "$$\n",
    "\\mathrm{ReLU}(x) = \\max(0,x) = \\frac{x + |x|}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1819c3ec-40a6-4cb9-bc97-0c58ecbd65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97af27bc-8774-4d6c-8b5d-bbe46e937fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = relu(linear(a0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6425907-d7da-4537-962d-d3ee9f5bf0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4229, 0.0000],\n",
       "        [0.3840, 0.0000],\n",
       "        [0.3086, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0d3f73-e377-4680-8d47-34c5b0f6a144",
   "metadata": {},
   "source": [
    "The effect of the ReLU function is as anticipated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faaed89-24b0-419e-b20f-3595da3862fc",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78228633-3b65-4981-bcf9-8f1d9e6c94f6",
   "metadata": {},
   "source": [
    "## Backward propagation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
