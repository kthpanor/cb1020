{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c6bf05-2e31-46b6-8a24-6e8bac97382d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# PyTorch\n",
    "\n",
    "[PyTorch](https://en.wikipedia.org/wiki/PyTorch) is a machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing. PyTorch provides two high-level features:\n",
    "\n",
    "- Tensor computing with acceleration via graphics processing units (GPUs)\n",
    "- Deep neural networks built on a tape-based automatic differentiation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f044dec-3842-4719-af51-781875b9c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb2939-a279-4162-b8f1-0b51b521235a",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "The central data abstraction in PyTorch is given by the `torch.tensor` class. It represents the counterpart of the `numpy.ndarray` class in NumPy, and many of the respective class methods have similar syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659ecc5c-383a-4d12-8080-e74895567339",
   "metadata": {},
   "source": [
    "### Tensor creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96366641-264e-4043-8f5c-d073ed9edb35",
   "metadata": {},
   "source": [
    "Ways to create PyTorch tensors include:\n",
    "\n",
    "- `torch.tensor()`\n",
    "- `torch.empty()`\n",
    "- `torch.zeros()`\n",
    "- `torch.ones()`\n",
    "- `torch.rand()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eccc351-9363-4820-be60-bf22b527ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3, 3, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a7c974-c503-4868-acf1-dd4f07f91bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2332, 0.4575, 0.9422],\n",
      "        [0.1645, 0.8829, 0.9889],\n",
      "        [0.0236, 0.0347, 0.6368]])\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310b3be-bf97-4ffd-992c-336a51a10896",
   "metadata": {},
   "source": [
    "By default, PyTorch tensors are populated with 32-bit (single precision) floating point numbers suitable for arithmetic operations on GPUs, but many other data types are available and include:\n",
    "\n",
    "- `torch.bool`\n",
    "- `torch.int8`\n",
    "- `torch.int16`\n",
    "- `torch.int32`\n",
    "- `torch.int64`\n",
    "- `torch.half` or `torch.float16`\n",
    "- `torch.float`\n",
    "- `torch.double` or `torch.float64`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaabecd-9cf0-4946-9bc5-129b989b2472",
   "metadata": {},
   "source": [
    "A PyTorch tensor can be converted to a regular Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01f18192-e2d7-4ca6-897d-6a7821306aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.23320060968399048, 0.4574585556983948, 0.9422464370727539],\n",
       " [0.16446655988693237, 0.8828853368759155, 0.9889333844184875],\n",
       " [0.02362501621246338, 0.03473007678985596, 0.6367791295051575]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6175487-afd5-4275-9636-9478f001c5da",
   "metadata": {},
   "source": [
    "Conversely, a Python list can be converted to a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88abbc97-078a-454a-b2be-9ebabd727162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2332, 0.4575, 0.9422],\n",
       "        [0.1645, 0.8829, 0.9889],\n",
       "        [0.0236, 0.0347, 0.6368]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(a.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e0d98-581a-4578-a4e0-8d3254699069",
   "metadata": {},
   "source": [
    "### Tensor operations\n",
    "\n",
    "PyTorch tensors have over three hundred operations that can be performed on them, including:\n",
    "\n",
    "- `torch.abs()`\n",
    "- `torch.max()`\n",
    "- `torch.mean()`\n",
    "- `torch.std()`\n",
    "- `torch.prod()`\n",
    "- `torch.unique()`\n",
    "- `torch.matmul()`\n",
    "- `torch.svd()`\n",
    "- `torch.sin()`\n",
    "- `torch.cos()`\n",
    "- `torch.flatten()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa48c00b-0b64-49c9-9a1a-5519930c21ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4849)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e0309c-93df-4509-8867-e3a6f4b80a8e",
   "metadata": {},
   "source": [
    "Note that a tensor with a scalar number is given in return. To instead get a Python number in return, we can perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca4d6f69-69a2-4531-9326-4c34125c3d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4849250018596649"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8802d60a-d627-4247-ab5d-83f97642def9",
   "metadata": {},
   "source": [
    "### NumPy bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5d2bf4-cb2c-43a8-aa2c-8cbb741340e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51233599-9c2d-4c5e-aa27-48cb2a79ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.ones((2, 3))\n",
    "pth_tensor = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "498c2ae8-55b3-4760-85ff-dd502be0615f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(pth_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5f1f5-299f-4b7c-82c8-82540e71f047",
   "metadata": {},
   "source": [
    "We note that the NumPy array default data type of float64 (double precision) is preserved. In fact, we merely created a pointer to the same data in memory such that a change in one object is reflected in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f44bd8d-3e35-4a37-a17b-44bb600e9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array[1, 2] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bee37edc-ac34-41aa-81bd-b072c35241ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified numpy array:\n",
      " [[1. 1. 1.]\n",
      " [1. 1. 2.]]\n",
      "Bridged pytorch tensor:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Modified numpy array:\\n\", np_array)\n",
    "print(\"Bridged pytorch tensor:\\n\", pth_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1471e1c6-44ec-434d-a292-bd767ddafba4",
   "metadata": {},
   "source": [
    "A reason to create a bridge between data can e.g. be to take advantage of the easy accessible  GPU acceleration available in PyTorch for scientific codes developed with NumPy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cd2249-5563-47a5-9120-f80601180f15",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7943a0e9-7780-4e50-91c0-f447e8aef8ea",
   "metadata": {},
   "source": [
    "The machine learning models in PyTorch are built as neural networks with layers of neurons. The input layers received input data; hidden layers transforms the data; and the output layer provides the results upon which model predictions are made.\n",
    "\n",
    "Every neuron has an associated activation level. The input level apart, activation levels in a given level, say $L$, are determined from those in the previous layer by use of weights that are collected in a matrix $\\boldsymbol{W}$ and biases that are collected in a row vector $\\boldsymbol{b}$. \n",
    "\n",
    "A layer is referred to as *linear* if the weights and biases are applied in a linear transformation\n",
    "\n",
    "$$\n",
    "\\boldsymbol{a}^{(L)} = f(\\boldsymbol{a}^{(L-1)} \\boldsymbol{W}^T \n",
    "+ \\boldsymbol{b})\n",
    "$$\n",
    "\n",
    "As indicated, to get the final activation levels also involves the elementwise operation of a  (typically) nonlinear activation function, $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80d91b9-fa63-4284-86dc-4b721e50aab7",
   "metadata": {},
   "source": [
    "![Neural Network](../images/neural_network.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e825b-c1b7-4201-9e95-e73f0dff4b3e",
   "metadata": {},
   "source": [
    "### Flatten tensors\n",
    "\n",
    "PyTorch receives input data in the form of batches of PyTorch tensors of rank 1. If data is stored as tensors of higher rank, they first need to be flattened. \n",
    "\n",
    "Let us assume having three $2\\times 2$ tensors as input, e.g. three greyscale images of two-by-two pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37d1fc2a-87d7-4a51-9789-ae0d23702b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "\n",
    "tensor_batch = torch.rand(batch_size, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42847885-e3f7-43c6-9556-d7a7b921fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = torch.nn.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cf9ab92-95f1-41c2-8fec-ca3dd7f4ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = flatten(tensor_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b418d45-34f4-4583-ba12-aaedb98ab6a2",
   "metadata": {},
   "source": [
    "These have now been flattened to become three row vectors of dimension four."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b4d3ae-41a4-4a9d-bb8d-daaf327b0f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6447, 0.9236, 0.2894, 0.3067],\n",
      "        [0.6588, 0.4814, 0.0097, 0.1238],\n",
      "        [0.0132, 0.8080, 0.1293, 0.4597]])\n"
     ]
    }
   ],
   "source": [
    "print(a0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745fd18-740c-4dc8-b491-61053c623cb3",
   "metadata": {},
   "source": [
    "### Layer transformations\n",
    "\n",
    "The linear layer transformation described above is achieved with the `torch.nn.Linear` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de014504-c10b-4909-8a0a-c4a0d885a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(4, 2, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ee301-14b9-4a1b-afa1-7c261c513558",
   "metadata": {},
   "source": [
    "Here we consider a transformation from an input layer with four neurons, $n_0 = 4$, to a hidden layer with only two, $n_1 = 2$.\n",
    "\n",
    "When instantiated, the hidden layer object receives weight and bias attributes that are initialized randomly with values\n",
    "\n",
    "$$\n",
    "-1/\\sqrt{n_0} < w_{ij}, b_i < 1 / \\sqrt{n_0}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e31176b8-a828-4448-af13-960a2b663e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2367,  0.4125,  0.0317, -0.1664],\n",
       "        [-0.0286, -0.0914, -0.1212, -0.2656]], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0cefe79-513f-461a-8556-0fbd8201bae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0288, 0.2220], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0698d17-e8da-4450-b85c-3dec87c97e65",
   "metadata": {},
   "source": [
    "Use PyToch to perform the layer transoformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac750bcc-4ebc-4442-89ad-d8ab601228b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5205, 0.0026],\n",
       "        [0.3630, 0.1251],\n",
       "        [0.2928, 0.0100]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(a0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0301857-d985-4791-ac59-b02e73e40d33",
   "metadata": {},
   "source": [
    "Check the transformation with an explicit calculation of the linear transformation:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{a}^{(0)} \\boldsymbol{W}^T \n",
    "+ \\boldsymbol{b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0cda628-033f-4d8b-b9d1-6207c06f02f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5205, 0.0026],\n",
       "        [0.3630, 0.1251],\n",
       "        [0.2928, 0.0100]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a0, linear.weight.T) + linear.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47851075-f623-49ce-a88f-bb75c4030322",
   "metadata": {},
   "source": [
    "We note that the two results are identical.\n",
    "\n",
    "Now remains the application of the nonlinear activation function, $f$, according to\n",
    "\n",
    "$$\n",
    "\\boldsymbol{a}^{(1)} =f( \n",
    "\\boldsymbol{a}^{(0)} \\boldsymbol{W}^T \n",
    "+ \\boldsymbol{b})\n",
    "$$\n",
    "\n",
    "A common choice in machine learning is to adopt the rectifier linear unit function\n",
    "\n",
    "$$\n",
    "\\mathrm{ReLU}(x) = \\max(0,x) = \\frac{x + |x|}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1819c3ec-40a6-4cb9-bc97-0c58ecbd65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97af27bc-8774-4d6c-8b5d-bbe46e937fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = relu(linear(a0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6425907-d7da-4537-962d-d3ee9f5bf0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5205, 0.0026],\n",
       "        [0.3630, 0.1251],\n",
       "        [0.2928, 0.0100]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0d3f73-e377-4680-8d47-34c5b0f6a144",
   "metadata": {},
   "source": [
    "The effect of the ReLU function is as anticipated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faaed89-24b0-419e-b20f-3595da3862fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d19f07f-d6d4-4563-9c70-3eba06d8f988",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In the process of training the network, we need a measure of closeness between the prediction in the output layer and the correct result. This measure is given by a *loss function*. Several [loss functions are available in PyTorch](https://pytorch.org/docs/stable/nn.html#loss-functions) for different purposes. In binary classification networks, the `CrossEntropyLoss()` is a typical choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f363818-4eab-40c3-9405-c756185e7223",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1597eeb8-d9fc-40dd-b459-59e2dd52438a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let us assume that we have four classes in the output layer and that we are concerned with a specific item in the data set for which the correct answer is class number three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b7f95160-ceb3-4ceb-91aa-89fd2b703663",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "correct_answer = torch.tensor([0.0, 0.0, 1.0, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eb851b-0799-46ac-a84c-1b72d8f75607",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let us further assume that we have made two separate predictions (one good and one bad) in the output layer leading to the following activity levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0f7bbee0-5c3e-483f-b80c-2793c5a631bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_prediction = torch.tensor([0.2, 0.5, 3.1, -0.1])\n",
    "\n",
    "bad_prediction = torch.tensor([2.0, 2.5, 1.1, -0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8153d4-e935-4138-91b7-5e9c0a215b9b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The associated loss function values (errors) are given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2829799e-8f82-40d8-ace3-2d6c7fda0f5b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good prediction loss = tensor(0.1571)\n",
      "bad prediction loss  = tensor(2.0434)\n"
     ]
    }
   ],
   "source": [
    "print(\"good prediction loss =\", loss_func(good_prediction, correct_answer))\n",
    "print(\"bad prediction loss  =\", loss_func(bad_prediction, correct_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102b8df4-8ada-4d87-a891-a68419bb37d2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As expected, the error is deemed much larger for the bad prediction.\n",
    "\n",
    "Let us see how PyTorch came this conclusion. \n",
    "\n",
    "In a first step, the predictions are exponentialized, promoting large positive numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b7a369fb-5afa-44be-a055-506b3b254b57",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1: good prediction loss = tensor([ 1.2214,  1.6487, 22.1979,  0.9048])\n",
      "step 1: bad prediction loss  = tensor([ 7.3891, 12.1825,  3.0042,  0.6065])\n"
     ]
    }
   ],
   "source": [
    "good_p1 = torch.exp(good_prediction)\n",
    "bad_p1 = torch.exp(bad_prediction)\n",
    "\n",
    "print(\"step 1: good prediction loss =\", good_p1)\n",
    "print(\"step 1: bad prediction loss  =\", bad_p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a0f3ee-88c6-4292-99be-4fc5461e3d71",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In a second step, a normalization is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "432eecb2-a01d-48ba-bcf1-babddc99f898",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2: good prediction loss = tensor([0.0470, 0.0635, 0.8547, 0.0348])\n",
      "step 2: bad prediction loss  = tensor([0.3187, 0.5255, 0.1296, 0.0262])\n"
     ]
    }
   ],
   "source": [
    "good_p2 = good_p1 / good_p1.sum()\n",
    "bad_p2 = bad_p1 / bad_p1.sum()\n",
    "\n",
    "print(\"step 2: good prediction loss =\", good_p2)\n",
    "print(\"step 2: bad prediction loss  =\", bad_p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccba709-be66-404f-a6ae-faa1d35177eb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In a third step, we take the negative logarithm so that a values close to one become close to zero (low loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e0d8d12d-d343-4bb2-8a3c-dfb88f6aef28",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3: good prediction loss = tensor([3.0571, 2.7571, 0.1571, 3.3571])\n",
      "step 3: bad prediction loss  = tensor([1.1434, 0.6434, 2.0434, 3.6434])\n"
     ]
    }
   ],
   "source": [
    "good_p3 = -torch.log(good_p2)\n",
    "bad_p3 = -torch.log(bad_p2)\n",
    "\n",
    "print(\"step 3: good prediction loss =\", good_p3)\n",
    "print(\"step 3: bad prediction loss  =\", bad_p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21584dc-626f-458b-9192-16281f60e9b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In a forth step, we pick out the loss for the binary correct answer by means of a product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "59f3e4a0-f2d2-425a-b3ac-3819f1186712",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4: good prediction loss = tensor([0.0000, 0.0000, 0.1571, 0.0000])\n",
      "step 4: bad prediction loss  = tensor([0.0000, 0.0000, 2.0434, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "good_p4 = good_p3 * correct_answer\n",
    "bad_p4 = bad_p3 * correct_answer\n",
    "\n",
    "print(\"step 4: good prediction loss =\", good_p4)\n",
    "print(\"step 4: bad prediction loss  =\", bad_p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfdd63e-a714-482e-a0f9-dfebc84dd5cf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In a fifth step, a summation is performed to produce a scalar loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7c7ed5ce-98b5-4dbc-b318-1349337a61ec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good prediction loss = tensor(0.1571)\n",
      "bad prediction loss  = tensor(2.0434)\n"
     ]
    }
   ],
   "source": [
    "print(\"good prediction loss =\", good_p4.sum())\n",
    "print(\"bad prediction loss  =\", bad_p4.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea2bacb-5902-432f-95ac-6bf4671a3c92",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We note that the resulting losses are identical to those obtained with the PyTorch loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78228633-3b65-4981-bcf9-8f1d9e6c94f6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Backward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee3c154-7b24-492a-8207-e63585c56f3a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
